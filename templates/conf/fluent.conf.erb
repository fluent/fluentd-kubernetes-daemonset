<% target = (dockerfile.split("/").last.split("-").last) %>
<% is_alpine = (dockerfile.split("/").last.split("-").first == "alpine") %>

# AUTOMATICALLY GENERATED
# DO NOT EDIT THIS FILE DIRECTLY, USE /templates/conf/fluent.conf.erb

<% if !is_alpine %>
@include systemd.conf
<% end%>
@include kubernetes.conf

<% case target when "elasticsearch"%>
<match **>
   type elasticsearch
   log_level info
   include_tag_key true
   host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
   port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
   logstash_format true
   buffer_chunk_limit 2M
   buffer_queue_limit 32
   flush_interval 5s
   max_retry_wait 30
   disable_retry_limit
   num_threads 8
</match>
<%  when "logentries"%>
<match **>
   type logentries
   use_json true
   tag_access_log stdout
   tag_error_log stderr
   config_path /etc/logentries/tokens.yaml
</match>
<%  when "loggly"%>
<match **>
   type loggly
   log_level info
   loggly_url "https://logs-01.loggly.com/inputs/#{ENV['LOGGLY_TOKEN']}/tag/fluentd"
</match>
<%  when "logzio"%>

<match kubernetes.**>
  type record_reformer
  <record>
    cluster "#{ENV['CLUSTER']}"
  </record>
  tag reformed.*
</match>

<match reformed.**>
   type logzio_buffered
   endpoint_url "https://listener.logz.io:8071?token=#{ENV['LOGZIO_TOKEN']}&type=#{ENV['LOGZIO_TYPE']}"
   output_include_time true
   output_include_tags true
   buffer_type    file
   buffer_path    /var/log/logzio-buffer
   flush_interval 10s
   buffer_chunk_limit 1m   # Logz.io has bulk limit of 10M. We recommend set this to 1M, to avoid oversized bulks
</match>
<%  when "cloudwatch"%>
<match **>
  type cloudwatch_logs
  log_group_name "#{ENV['LOG_GROUP_NAME']}"
  auto_create_stream true
  use_tag_as_stream true
</match>
<% end%>
